{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Práctica 2\n",
    "\n",
    "Objetivo: comprender cada técnica de *preparación de datos* y *selección de características*.\n",
    "\n",
    "\n",
    "\n",
    "**Contenido**\n",
    "1. Imports y utilidades\n",
    "2. Línea base (escalado + regresión logística)\n",
    "3. Imputación (comparación con eliminar filas perdidas)\n",
    "4. Selección tipo filtro (f\\_classif y chi2)\n",
    "5. RFECV (eliminación recursiva con validación cruzada)\n",
    "6. SelectFromModel (L1 y Random Forest)\n",
    "7. Selección de instancias\n",
    "8. (Opcional) Demostración con `Pipeline`\n",
    "9. (Opcional) Mini ejemplo de **regresión**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934d05a0",
   "metadata": {},
   "source": [
    "## 1) Imports y utilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (569, 30) | y shape: (569,)\n",
      "Train: (426, 30) | Test: (143, 30)\n"
     ]
    }
   ],
   "source": [
    "# 1) Configuración y carga del dataset (clasificación)\n",
    "import warnings, time\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Diferentes datasets de clasificación y regresión que se pueden usar\n",
    "from sklearn.datasets import load_breast_cancer, fetch_california_housing, load_diabetes\n",
    "\n",
    "# Algunas utilidades\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.metrics import accuracy_score, f1_score, mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.linear_model import LogisticRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, f_regression, chi2, RFECV, SelectFromModel\n",
    "\n",
    "RANDOM_STATE = 0\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "def standardize_train_test(Xtr, Xte):\n",
    "    sc = StandardScaler()\n",
    "    return sc.fit_transform(Xtr), sc.transform(Xte)\n",
    "\n",
    "def simulate_missingness(X, missing_rate=0.05, seed=RANDOM_STATE):\n",
    "    rng = np.random.RandomState(seed)\n",
    "    X2 = X.astype(float).copy()\n",
    "    n, d = X2.shape\n",
    "    m = int(missing_rate * n * d)\n",
    "    idx = rng.choice(n*d, m, replace=False)\n",
    "    X2[idx // d, idx % d] = np.nan\n",
    "    return X2\n",
    "\n",
    "# Cargamos un problema de clasificación: Breast Cancer (binaria)\n",
    "data = load_breast_cancer()\n",
    "X, y = data.data, data.target\n",
    "print('X shape:', X.shape, '| y shape:', y.shape)\n",
    "\n",
    "# Partición train/test estratificada\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, stratify=y, random_state=RANDOM_STATE\n",
    ")\n",
    "print('Train:', X_train.shape, '| Test:', X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Línea base (escalado + clasificador sencillo)\n",
    "Entrenamos sin selección ni imputación en un dataset sin valores perdidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BASELINE\n",
      "Accuracy: 0.9580  |  F1-macro: 0.9550  |  tiempo: 0.003s\n"
     ]
    }
   ],
   "source": [
    "# Escalado\n",
    "Xtr_s, Xte_s = standardize_train_test(X_train, X_test)\n",
    "\n",
    "# Clasificador ligero (rápido en aula)\n",
    "clf_base = LogisticRegression(penalty='l2', solver='liblinear', random_state=RANDOM_STATE)\n",
    "t0 = time.perf_counter(); clf_base.fit(Xtr_s, y_train); t_base = time.perf_counter() - t0\n",
    "yp = clf_base.predict(Xte_s)\n",
    "acc_base = accuracy_score(y_test, yp)\n",
    "f1_base = f1_score(y_test, yp, average='macro')\n",
    "\n",
    "print('BASELINE')\n",
    "print(f'Accuracy: {acc_base:.4f}  |  F1-macro: {f1_base:.4f}  |  tiempo: {t_base:.3f}s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Imputación (comparación con eliminar filas perdidas)\n",
    "Simulamos un **5%** de valores perdidos y comparamos:\n",
    "- **Eliminar filas con NaN** (train y test por separado)\n",
    "- **Imputación simple** (media)\n",
    "- **Imputación KNN** (k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ba021dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulamos valores perdidos\n",
    "Xtr_m = simulate_missingness(X_train, 0.05)\n",
    "Xte_m = simulate_missingness(X_test, 0.05)\n",
    "res_imput = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "dae56581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A) Eliminar filas con NaN (cuidado: reducimos datos)\n",
    "mask_tr = ~np.isnan(Xtr_m).any(axis=1)\n",
    "mask_te = ~np.isnan(Xte_m).any(axis=1)\n",
    "Xtr_drop, ytr_drop = Xtr_m[mask_tr], y_train[mask_tr]\n",
    "Xte_drop, yte_drop = Xte_m[mask_te], y_test[mask_te]\n",
    "Xtr_s, Xte_s = standardize_train_test(Xtr_drop, Xte_drop)\n",
    "clf = LogisticRegression(solver=\"liblinear\", random_state=RANDOM_STATE)\n",
    "t0 = time.perf_counter()\n",
    "clf.fit(Xtr_s, ytr_drop)\n",
    "t = time.perf_counter() - t0\n",
    "yp = clf.predict(Xte_s)\n",
    "res_imput.append(\n",
    "    [\n",
    "        \"Eliminar filas\",\n",
    "        Xtr_drop.shape[0],\n",
    "        Xte_drop.shape[0],\n",
    "        accuracy_score(yte_drop, yp),\n",
    "        f1_score(yte_drop, yp, average=\"macro\"),\n",
    "        t,\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f6ac391d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# B) SimpleImputer (media)\n",
    "imp = SimpleImputer(strategy=\"mean\")\n",
    "Xtr_imp = imp.fit_transform(Xtr_m)\n",
    "Xte_imp = imp.transform(Xte_m)\n",
    "Xtr_s, Xte_s = standardize_train_test(Xtr_imp, Xte_imp)\n",
    "clf = LogisticRegression(solver=\"liblinear\", random_state=RANDOM_STATE)\n",
    "t0 = time.perf_counter()\n",
    "clf.fit(Xtr_s, y_train)\n",
    "t = time.perf_counter() - t0\n",
    "yp = clf.predict(Xte_s)\n",
    "res_imput.append(\n",
    "    [\n",
    "        \"Imputación: media\",\n",
    "        Xtr_imp.shape[0],\n",
    "        Xte_imp.shape[0],\n",
    "        accuracy_score(y_test, yp),\n",
    "        f1_score(y_test, yp, average=\"macro\"),\n",
    "        t,\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c9c662c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C) KNNImputer (k=5)\n",
    "imp = KNNImputer(n_neighbors=5)\n",
    "Xtr_imp = imp.fit_transform(Xtr_m)\n",
    "Xte_imp = imp.transform(Xte_m)\n",
    "Xtr_s, Xte_s = standardize_train_test(Xtr_imp, Xte_imp)\n",
    "clf = LogisticRegression(solver=\"liblinear\", random_state=RANDOM_STATE)\n",
    "t0 = time.perf_counter()\n",
    "clf.fit(Xtr_s, y_train)\n",
    "t = time.perf_counter() - t0\n",
    "yp = clf.predict(Xte_s)\n",
    "res_imput.append(\n",
    "    [\n",
    "        \"Imputación: KNN (k=5)\",\n",
    "        Xtr_imp.shape[0],\n",
    "        Xte_imp.shape[0],\n",
    "        accuracy_score(y_test, yp),\n",
    "        f1_score(y_test, yp, average=\"macro\"),\n",
    "        t,\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4146fa1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OBLIGATORIO: Añade otro método de imputación básico\n",
    "# Utilizamos imputación con la mediana\n",
    "imp = SimpleImputer(strategy=\"median\")\n",
    "Xtr_imp = imp.fit_transform(Xtr_m)\n",
    "Xte_imp = imp.transform(Xte_m)\n",
    "Xtr_s, Xte_s = standardize_train_test(Xtr_imp, Xte_imp)\n",
    "clf = LogisticRegression(solver=\"liblinear\", random_state=RANDOM_STATE)\n",
    "t0 = time.perf_counter()\n",
    "clf.fit(Xtr_s, y_train)\n",
    "t = time.perf_counter() - t0\n",
    "yp = clf.predict(Xte_s)\n",
    "res_imput.append(\n",
    "    [\n",
    "        \"Imputación: mediana\",\n",
    "        Xtr_imp.shape[0],\n",
    "        Xte_imp.shape[0],\n",
    "        accuracy_score(y_test, yp),\n",
    "        f1_score(y_test, yp, average=\"macro\"),\n",
    "        t,\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "92718fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OBLIGATORIO: Añade otro método de imputación avanzado\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "imp = IterativeImputer(\n",
    "    estimator=SVR(kernel=\"rbf\", C=10, epsilon=0.1, gamma=\"scale\"),\n",
    "    initial_strategy=\"median\",\n",
    "    max_iter=10,\n",
    "    random_state=0,\n",
    ")\n",
    "\n",
    "Xtr_imp = imp.fit_transform(Xtr_m)\n",
    "Xte_imp = imp.transform(Xte_m)\n",
    "Xtr_s, Xte_s = standardize_train_test(Xtr_imp, Xte_imp)\n",
    "clf = LogisticRegression(solver=\"liblinear\", random_state=RANDOM_STATE)\n",
    "t0 = time.perf_counter()\n",
    "clf.fit(Xtr_s, y_train)\n",
    "t = time.perf_counter() - t0\n",
    "yp = clf.predict(Xte_s)\n",
    "res_imput.append(\n",
    "    [\n",
    "        \"Imputación: SVR\",\n",
    "        Xtr_imp.shape[0],\n",
    "        Xte_imp.shape[0],\n",
    "        accuracy_score(y_test, yp),\n",
    "        f1_score(y_test, yp, average=\"macro\"),\n",
    "        t,\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5442addb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Eliminar filas', 90, 33, 0.9393939393939394, 0.9379699248120301, 0.001662900000155787]\n",
      "['Imputación: media', 426, 143, 0.965034965034965, 0.9623783214943435, 0.0033559999992576195]\n",
      "['Imputación: KNN (k=5)', 426, 143, 0.958041958041958, 0.9550314465408805, 0.0032467999999425956]\n",
      "['Imputación: mediana', 426, 143, 0.958041958041958, 0.9550314465408805, 0.0033247000001210836]\n",
      "['Imputación: SVR', 426, 143, 0.9370629370629371, 0.9322809786898185, 0.003037899999981164]\n"
     ]
    }
   ],
   "source": [
    "for fila in res_imput:\n",
    "    print (fila)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5d6814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (20640, 8) | y shape: (20640,)\n",
      "['Imputación: media', 15480, 5160, 0.6320492952950263, 0.5218451545074996, 0.0030262000000220723]\n",
      "['Imputación: KNN (k=5)', 15480, 5160, 0.5752163798324154, 0.5648401141003718, 0.001670199999352917]\n",
      "['Imputación: mediana', 15480, 5160, 0.6481031351028333, 0.5097001820346163, 0.002002600000196253]\n",
      "['Imputación: SVR', 15480, 5160, 0.6351649509503047, 0.5194881139102752, 0.0018387000000075204]\n"
     ]
    }
   ],
   "source": [
    "# OPCIONAL: Usa un dataset de regresión, repite todos los métodos de imputación y muestra los resultados.\n",
    "# No olvides adaptar todas las métricas: Accuracy/F1 solo sirven para problemas de clasificación\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "data2 = fetch_california_housing()\n",
    "X, y = data2.data, data2.target\n",
    "print('X shape:', X.shape, '| y shape:', y.shape)\n",
    "\n",
    "# Partición train/test estratificada\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "Xtr_m = simulate_missingness(X_train, 0.05)\n",
    "Xte_m = simulate_missingness(X_test, 0.05)\n",
    "res_imput = []\n",
    "\n",
    "# B) SimpleImputer (media)\n",
    "imp = SimpleImputer(strategy=\"mean\")\n",
    "Xtr_imp = imp.fit_transform(Xtr_m)\n",
    "Xte_imp = imp.transform(Xte_m)\n",
    "Xtr_s, Xte_s = standardize_train_test(Xtr_imp, Xte_imp)\n",
    "clf = LinearRegression()\n",
    "t0 = time.perf_counter()\n",
    "clf.fit(Xtr_s, y_train)\n",
    "t = time.perf_counter() - t0\n",
    "yp = clf.predict(Xte_s)\n",
    "res_imput.append(\n",
    "    [\n",
    "        \"Imputación: media\",\n",
    "        Xtr_imp.shape[0],\n",
    "        Xte_imp.shape[0],\n",
    "        mean_squared_error(y_test, yp),\n",
    "        r2_score(y_test, yp),\n",
    "        t,\n",
    "    ]\n",
    ")\n",
    "\n",
    "# C) KNNImputer (k=5)\n",
    "imp = KNNImputer(n_neighbors=5)\n",
    "Xtr_imp = imp.fit_transform(Xtr_m)\n",
    "Xte_imp = imp.transform(Xte_m)\n",
    "Xtr_s, Xte_s = standardize_train_test(Xtr_imp, Xte_imp)\n",
    "clf = LinearRegression()\n",
    "t0 = time.perf_counter()\n",
    "clf.fit(Xtr_s, y_train)\n",
    "t = time.perf_counter() - t0\n",
    "yp = clf.predict(Xte_s)\n",
    "res_imput.append(\n",
    "    [\n",
    "        \"Imputación: KNN (k=5)\",\n",
    "        Xtr_imp.shape[0],\n",
    "        Xte_imp.shape[0],\n",
    "        mean_squared_error(y_test, yp),\n",
    "        r2_score(y_test, yp),\n",
    "        t,\n",
    "    ]\n",
    ")\n",
    "\n",
    "# OBLIGATORIO: Añade otro método de imputación básico\n",
    "# Utilizamos imputación con la mediana\n",
    "imp = SimpleImputer(strategy=\"median\")\n",
    "Xtr_imp = imp.fit_transform(Xtr_m)\n",
    "Xte_imp = imp.transform(Xte_m)\n",
    "Xtr_s, Xte_s = standardize_train_test(Xtr_imp, Xte_imp)\n",
    "clf = LinearRegression()\n",
    "t0 = time.perf_counter()\n",
    "clf.fit(Xtr_s, y_train)\n",
    "t = time.perf_counter() - t0\n",
    "yp = clf.predict(Xte_s)\n",
    "res_imput.append(\n",
    "    [\n",
    "        \"Imputación: mediana\",\n",
    "        Xtr_imp.shape[0],\n",
    "        Xte_imp.shape[0],\n",
    "        mean_squared_error(y_test, yp),\n",
    "        r2_score(y_test, yp),\n",
    "        t,\n",
    "    ]\n",
    ")\n",
    "\n",
    "# OBLIGATORIO: Añade otro método de imputación avanzado\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "imp = IterativeImputer(\n",
    "    estimator=SVR(kernel=\"rbf\", C=10, epsilon=0.1, gamma=\"scale\"),\n",
    "    initial_strategy=\"median\",\n",
    "    max_iter=10,\n",
    "    random_state=0,\n",
    ")\n",
    "\n",
    "Xtr_imp = imp.fit_transform(Xtr_m)\n",
    "Xte_imp = imp.transform(Xte_m)\n",
    "Xtr_s, Xte_s = standardize_train_test(Xtr_imp, Xte_imp)\n",
    "clf = LinearRegression()\n",
    "t0 = time.perf_counter()\n",
    "clf.fit(Xtr_s, y_train)\n",
    "t = time.perf_counter() - t0\n",
    "yp = clf.predict(Xte_s)\n",
    "res_imput.append(\n",
    "    [\n",
    "        \"Imputación: SVR\",\n",
    "        Xtr_imp.shape[0],\n",
    "        Xte_imp.shape[0],\n",
    "        mean_squared_error(y_test, yp),\n",
    "        r2_score(y_test, yp),\n",
    "        t,\n",
    "    ]\n",
    ")\n",
    "\n",
    "for fila in res_imput:\n",
    "    print (fila)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f19741c",
   "metadata": {},
   "source": [
    "### ENTREGABLE: Escribe en el documento de la práctica (formato libre) un texto explicando los resultados obtenidos y decidiendo cuál es el mejor método de imputación en cada caso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tratamiento</th>\n",
       "      <th>n_train</th>\n",
       "      <th>n_test</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1-macro</th>\n",
       "      <th>tiempo_entreno_s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Imputación: media</td>\n",
       "      <td>15480</td>\n",
       "      <td>5160</td>\n",
       "      <td>0.632049</td>\n",
       "      <td>0.521845</td>\n",
       "      <td>0.003026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Imputación: KNN (k=5)</td>\n",
       "      <td>15480</td>\n",
       "      <td>5160</td>\n",
       "      <td>0.575216</td>\n",
       "      <td>0.564840</td>\n",
       "      <td>0.001670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Imputación: mediana</td>\n",
       "      <td>15480</td>\n",
       "      <td>5160</td>\n",
       "      <td>0.648103</td>\n",
       "      <td>0.509700</td>\n",
       "      <td>0.002003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Imputación: SVR</td>\n",
       "      <td>15480</td>\n",
       "      <td>5160</td>\n",
       "      <td>0.635165</td>\n",
       "      <td>0.519488</td>\n",
       "      <td>0.001839</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Tratamiento  n_train  n_test  Accuracy  F1-macro  \\\n",
       "0      Imputación: media    15480    5160  0.632049  0.521845   \n",
       "1  Imputación: KNN (k=5)    15480    5160  0.575216  0.564840   \n",
       "2    Imputación: mediana    15480    5160  0.648103  0.509700   \n",
       "3        Imputación: SVR    15480    5160  0.635165  0.519488   \n",
       "\n",
       "   tiempo_entreno_s  \n",
       "0          0.003026  \n",
       "1          0.001670  \n",
       "2          0.002003  \n",
       "3          0.001839  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mostramos resultados\n",
    "df_imput = pd.DataFrame(res_imput, columns=['Tratamiento', 'n_train', 'n_test', 'Accuracy', 'F1-macro', 'tiempo_entreno_s'])\n",
    "df_imput"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Selección tipo filtro\n",
    "Comparamos *sin selección* vs **SelectKBest** con:\n",
    "- `f_classif` (general)\n",
    "- `chi2` (requiere no-negatividad, debemos aplicar `MinMaxScaler` antes de usarlo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4621a8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usamos los datos SIN NaN (X_train / X_test originales)\n",
    "imp = SimpleImputer()  # por seguridad\n",
    "Xtr = imp.fit_transform(X_train)\n",
    "Xte = imp.transform(X_test)\n",
    "Xtr_s0, Xte_s0 = standardize_train_test(Xtr, Xte)\n",
    "\n",
    "# Baseline\n",
    "clf = LogisticRegression(solver=\"liblinear\", random_state=RANDOM_STATE)\n",
    "t0 = time.perf_counter()\n",
    "clf.fit(Xtr_s0, y_train)\n",
    "t_base2 = time.perf_counter() - t0\n",
    "yp = clf.predict(Xte_s0)\n",
    "acc0 = accuracy_score(y_test, yp)\n",
    "f10 = f1_score(y_test, yp, average=\"macro\")\n",
    "\n",
    "rows = [[\"Sin selección\", Xtr.shape[1], acc0, f10, t_base2]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e22bb789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SelectKBest f_classif (k=10)\n",
    "k = min(10, Xtr.shape[1])\n",
    "sel = SelectKBest(score_func=f_classif, k=k)\n",
    "Xtr_k = sel.fit_transform(Xtr_s0, y_train)\n",
    "Xte_k = sel.transform(Xte_s0)\n",
    "clf = LogisticRegression(solver=\"liblinear\", random_state=RANDOM_STATE)\n",
    "t0 = time.perf_counter()\n",
    "clf.fit(Xtr_k, y_train)\n",
    "t1 = time.perf_counter() - t0\n",
    "yp = clf.predict(Xte_k)\n",
    "rows.append(\n",
    "    [\n",
    "        f\"SelectKBest f_classif (k={k})\",\n",
    "        k,\n",
    "        accuracy_score(y_test, yp),\n",
    "        f1_score(y_test, yp, average=\"macro\"),\n",
    "        t1,\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SelectKBest chi2 (k=10) → MinMax\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "mm = MinMaxScaler()\n",
    "Xtr_mm = mm.fit_transform(Xtr)\n",
    "Xte_mm = mm.transform(Xte)\n",
    "sel = SelectKBest(score_func=chi2, k=k)\n",
    "Xtr_k2 = sel.fit_transform(Xtr_mm, y_train)\n",
    "Xte_k2 = sel.transform(Xte_mm)\n",
    "clf = LogisticRegression(solver='liblinear', random_state=RANDOM_STATE)\n",
    "t0 = time.perf_counter(); clf.fit(Xtr_k2, y_train); t2 = time.perf_counter() - t0\n",
    "yp = clf.predict(Xte_k2)\n",
    "rows.append([f'SelectKBest chi2 (k={k})', k, accuracy_score(y_test, yp), f1_score(y_test, yp, average='macro'), t2])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd89d245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sin selección', 30, 0.958041958041958, 0.9550314465408805, 0.003491500000563974]\n",
      "['SelectKBest f_classif (k=10)', 10, 0.951048951048951, 0.947329650092081, 0.002073200000268116]\n",
      "['SelectKBest chi2 (k=10)', 10, 0.9300699300699301, 0.9244505494505495, 0.001654200000302808]\n",
      "['SelectKBest f_classif (k=5)', 5, 0.9300699300699301, 0.9250524109014675, 0.001465999999709311]\n",
      "['SelectKBest chi2 (k=5)', 5, 0.9300699300699301, 0.9244505494505495, 0.0022325999998429324]\n",
      "['SelectKBest f_classif (k=20)', 20, 0.965034965034965, 0.9620669531540135, 0.0023682999999437016]\n",
      "['SelectKBest chi2 (k=20)', 20, 0.9440559440559441, 0.9390451832907076, 0.003485000000182481]\n"
     ]
    }
   ],
   "source": [
    "# OBLIGATORIO: Prueba con diferentes valores de n_features\n",
    "k = min(5, Xtr.shape[1])\n",
    "sel = SelectKBest(score_func=f_classif, k=k)\n",
    "Xtr_k = sel.fit_transform(Xtr_s0, y_train)\n",
    "Xte_k = sel.transform(Xte_s0)\n",
    "clf = LogisticRegression(solver=\"liblinear\", random_state=RANDOM_STATE)\n",
    "t0 = time.perf_counter()\n",
    "clf.fit(Xtr_k, y_train)\n",
    "t1 = time.perf_counter() - t0\n",
    "yp = clf.predict(Xte_k)\n",
    "rows.append(\n",
    "    [\n",
    "        f\"SelectKBest f_classif (k={k})\",\n",
    "        k,\n",
    "        accuracy_score(y_test, yp),\n",
    "        f1_score(y_test, yp, average=\"macro\"),\n",
    "        t1,\n",
    "    ]\n",
    ")\n",
    "\n",
    "Xtr_mm = mm.fit_transform(Xtr)\n",
    "Xte_mm = mm.transform(Xte)\n",
    "sel = SelectKBest(score_func=chi2, k=k)\n",
    "Xtr_k2 = sel.fit_transform(Xtr_mm, y_train)\n",
    "Xte_k2 = sel.transform(Xte_mm)\n",
    "clf = LogisticRegression(solver='liblinear', random_state=RANDOM_STATE)\n",
    "t0 = time.perf_counter(); clf.fit(Xtr_k2, y_train); t2 = time.perf_counter() - t0\n",
    "yp = clf.predict(Xte_k2)\n",
    "rows.append([f'SelectKBest chi2 (k={k})', k, accuracy_score(y_test, yp), f1_score(y_test, yp, average='macro'), t2])\n",
    "\n",
    "k = min(20, Xtr.shape[1])\n",
    "sel = SelectKBest(score_func=f_classif, k=k)\n",
    "Xtr_k = sel.fit_transform(Xtr_s0, y_train)\n",
    "Xte_k = sel.transform(Xte_s0)\n",
    "clf = LogisticRegression(solver=\"liblinear\", random_state=RANDOM_STATE)\n",
    "t0 = time.perf_counter()\n",
    "clf.fit(Xtr_k, y_train)\n",
    "t1 = time.perf_counter() - t0\n",
    "yp = clf.predict(Xte_k)\n",
    "rows.append(\n",
    "    [\n",
    "        f\"SelectKBest f_classif (k={k})\",\n",
    "        k,\n",
    "        accuracy_score(y_test, yp),\n",
    "        f1_score(y_test, yp, average=\"macro\"),\n",
    "        t1,\n",
    "    ]\n",
    ")\n",
    "\n",
    "Xtr_mm = mm.fit_transform(Xtr)\n",
    "Xte_mm = mm.transform(Xte)\n",
    "sel = SelectKBest(score_func=chi2, k=k)\n",
    "Xtr_k2 = sel.fit_transform(Xtr_mm, y_train)\n",
    "Xte_k2 = sel.transform(Xte_mm)\n",
    "clf = LogisticRegression(solver='liblinear', random_state=RANDOM_STATE)\n",
    "t0 = time.perf_counter(); clf.fit(Xtr_k2, y_train); t2 = time.perf_counter() - t0\n",
    "yp = clf.predict(Xte_k2)\n",
    "rows.append([f'SelectKBest chi2 (k={k})', k, accuracy_score(y_test, yp), f1_score(y_test, yp, average='macro'), t2])\n",
    "\n",
    "for fila in rows:\n",
    "    print (fila)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "64bd4cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OBLIGATORIO: Usa un segundo problema de clasificación y repite todo\n",
    "# No escoger digits -> Ejemplo para usar \"Wines\" (Hay que buscar)\n",
    "from sklearn.datasets import load_wine\n",
    "data3 = load_wine()\n",
    "X, y = data3.data, data3.target\n",
    "\n",
    "# Partición train/test estratificada\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "Xtr_m = simulate_missingness(X_train, 0.05)\n",
    "Xte_m = simulate_missingness(X_test, 0.05)\n",
    "res_imput = []\n",
    "\n",
    "imp = SimpleImputer()  # por seguridad\n",
    "Xtr = imp.fit_transform(X_train)\n",
    "Xte = imp.transform(X_test)\n",
    "Xtr_s0, Xte_s0 = standardize_train_test(Xtr, Xte)\n",
    "\n",
    "# Baseline\n",
    "clf = LogisticRegression(solver=\"liblinear\", random_state=RANDOM_STATE)\n",
    "t0 = time.perf_counter()\n",
    "clf.fit(Xtr_s0, y_train)\n",
    "t_base2 = time.perf_counter() - t0\n",
    "yp = clf.predict(Xte_s0)\n",
    "acc0 = accuracy_score(y_test, yp)\n",
    "f10 = f1_score(y_test, yp, average=\"macro\")\n",
    "\n",
    "rows = [[\"Sin selección\", Xtr.shape[1], acc0, f10, t_base2]]\n",
    "\n",
    "\n",
    "k = min(10, Xtr.shape[1])\n",
    "sel = SelectKBest(score_func=f_classif, k=k)\n",
    "Xtr_k = sel.fit_transform(Xtr_s0, y_train)\n",
    "Xte_k = sel.transform(Xte_s0)\n",
    "clf = LogisticRegression(solver=\"liblinear\", random_state=RANDOM_STATE)\n",
    "t0 = time.perf_counter()\n",
    "clf.fit(Xtr_k, y_train)\n",
    "t1 = time.perf_counter() - t0\n",
    "yp = clf.predict(Xte_k)\n",
    "rows.append(\n",
    "    [\n",
    "        f\"SelectKBest f_classif Wines (k={k})\",\n",
    "        k,\n",
    "        accuracy_score(y_test, yp),\n",
    "        f1_score(y_test, yp, average=\"macro\"),\n",
    "        t1,\n",
    "    ]\n",
    ")\n",
    "\n",
    "mm = MinMaxScaler()\n",
    "Xtr_mm = mm.fit_transform(Xtr)\n",
    "Xte_mm = mm.transform(Xte)\n",
    "sel = SelectKBest(score_func=chi2, k=k)\n",
    "Xtr_k2 = sel.fit_transform(Xtr_mm, y_train)\n",
    "Xte_k2 = sel.transform(Xte_mm)\n",
    "clf = LogisticRegression(solver='liblinear', random_state=RANDOM_STATE)\n",
    "t0 = time.perf_counter(); clf.fit(Xtr_k2, y_train); t2 = time.perf_counter() - t0\n",
    "yp = clf.predict(Xte_k2)\n",
    "rows.append([f'SelectKBest chi2 Wines (k={k})', k, accuracy_score(y_test, yp), f1_score(y_test, yp, average='macro'), t2])\n",
    "\n",
    "k = min(5, Xtr.shape[1])\n",
    "sel = SelectKBest(score_func=f_classif, k=k)\n",
    "Xtr_k = sel.fit_transform(Xtr_s0, y_train)\n",
    "Xte_k = sel.transform(Xte_s0)\n",
    "clf = LogisticRegression(solver=\"liblinear\", random_state=RANDOM_STATE)\n",
    "t0 = time.perf_counter()\n",
    "clf.fit(Xtr_k, y_train)\n",
    "t1 = time.perf_counter() - t0\n",
    "yp = clf.predict(Xte_k)\n",
    "rows.append(\n",
    "    [\n",
    "        f\"SelectKBest f_classif Wines (k={k})\",\n",
    "        k,\n",
    "        accuracy_score(y_test, yp),\n",
    "        f1_score(y_test, yp, average=\"macro\"),\n",
    "        t1,\n",
    "    ]\n",
    ")\n",
    "\n",
    "Xtr_mm = mm.fit_transform(Xtr)\n",
    "Xte_mm = mm.transform(Xte)\n",
    "sel = SelectKBest(score_func=chi2, k=k)\n",
    "Xtr_k2 = sel.fit_transform(Xtr_mm, y_train)\n",
    "Xte_k2 = sel.transform(Xte_mm)\n",
    "clf = LogisticRegression(solver='liblinear', random_state=RANDOM_STATE)\n",
    "t0 = time.perf_counter(); clf.fit(Xtr_k2, y_train); t2 = time.perf_counter() - t0\n",
    "yp = clf.predict(Xte_k2)\n",
    "rows.append([f'SelectKBest chi2 Wines (k={k})', k, accuracy_score(y_test, yp), f1_score(y_test, yp, average='macro'), t2])\n",
    "\n",
    "k = min(20, Xtr.shape[1])\n",
    "sel = SelectKBest(score_func=f_classif, k=k)\n",
    "Xtr_k = sel.fit_transform(Xtr_s0, y_train)\n",
    "Xte_k = sel.transform(Xte_s0)\n",
    "clf = LogisticRegression(solver=\"liblinear\", random_state=RANDOM_STATE)\n",
    "t0 = time.perf_counter()\n",
    "clf.fit(Xtr_k, y_train)\n",
    "t1 = time.perf_counter() - t0\n",
    "yp = clf.predict(Xte_k)\n",
    "rows.append(\n",
    "    [\n",
    "        f\"SelectKBest f_classif Wines(k={k})\",\n",
    "        k,\n",
    "        accuracy_score(y_test, yp),\n",
    "        f1_score(y_test, yp, average=\"macro\"),\n",
    "        t1,\n",
    "    ]\n",
    ")\n",
    "\n",
    "Xtr_mm = mm.fit_transform(Xtr)\n",
    "Xte_mm = mm.transform(Xte)\n",
    "sel = SelectKBest(score_func=chi2, k=k)\n",
    "Xtr_k2 = sel.fit_transform(Xtr_mm, y_train)\n",
    "Xte_k2 = sel.transform(Xte_mm)\n",
    "clf = LogisticRegression(solver='liblinear', random_state=RANDOM_STATE)\n",
    "t0 = time.perf_counter(); clf.fit(Xtr_k2, y_train); t2 = time.perf_counter() - t0\n",
    "yp = clf.predict(Xte_k2)\n",
    "rows.append([f'SelectKBest chi2 Wines (k={k})', k, accuracy_score(y_test, yp), f1_score(y_test, yp, average='macro'), t2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa6b203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPCIONAL: Usa un problema de regresión, adapta lo necesario y repite todo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "274b278f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tratamiento</th>\n",
       "      <th>n_features</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1-macro</th>\n",
       "      <th>tiempo_entreno_s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sin selección</td>\n",
       "      <td>13</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.001855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SelectKBest f_classif Wines (k=10)</td>\n",
       "      <td>10</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.001657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SelectKBest chi2 Wines (k=10)</td>\n",
       "      <td>10</td>\n",
       "      <td>0.977778</td>\n",
       "      <td>0.972262</td>\n",
       "      <td>0.002043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SelectKBest f_classif Wines (k=5)</td>\n",
       "      <td>5</td>\n",
       "      <td>0.977778</td>\n",
       "      <td>0.972262</td>\n",
       "      <td>0.001288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SelectKBest chi2 Wines (k=5)</td>\n",
       "      <td>5</td>\n",
       "      <td>0.911111</td>\n",
       "      <td>0.908267</td>\n",
       "      <td>0.001175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SelectKBest f_classif Wines(k=13)</td>\n",
       "      <td>13</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.001630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SelectKBest chi2 Wines (k=13)</td>\n",
       "      <td>13</td>\n",
       "      <td>0.977778</td>\n",
       "      <td>0.972262</td>\n",
       "      <td>0.001445</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Tratamiento  n_features  Accuracy  F1-macro  \\\n",
       "0                       Sin selección          13  1.000000  1.000000   \n",
       "1  SelectKBest f_classif Wines (k=10)          10  1.000000  1.000000   \n",
       "2       SelectKBest chi2 Wines (k=10)          10  0.977778  0.972262   \n",
       "3   SelectKBest f_classif Wines (k=5)           5  0.977778  0.972262   \n",
       "4        SelectKBest chi2 Wines (k=5)           5  0.911111  0.908267   \n",
       "5   SelectKBest f_classif Wines(k=13)          13  1.000000  1.000000   \n",
       "6       SelectKBest chi2 Wines (k=13)          13  0.977778  0.972262   \n",
       "\n",
       "   tiempo_entreno_s  \n",
       "0          0.001855  \n",
       "1          0.001657  \n",
       "2          0.002043  \n",
       "3          0.001288  \n",
       "4          0.001175  \n",
       "5          0.001630  \n",
       "6          0.001445  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    rows,\n",
    "    columns=[\"Tratamiento\", \"n_features\", \"Accuracy\", \"F1-macro\", \"tiempo_entreno_s\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f284a72",
   "metadata": {},
   "source": [
    "### ENTREGABLE: Escribe en el documento de la práctica (formato libre) un texto explicando los resultados obtenidos y decidiendo cuál es el mejor número de características en cada caso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) RFECV\n",
    "Usamos **RFECV** para encontrar automáticamente cuántas características dejar. Después reentrenamos una RL con esas características."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFECV\n",
      "n_features seleccionadas: 6\n",
      "Accuracy: 0.9441  |  F1-macro: 0.9400  |  tiempo_total: 3.012s\n"
     ]
    }
   ],
   "source": [
    "data = load_breast_cancer()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, stratify=y, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "Xtr_s, Xte_s = standardize_train_test(X_train, X_test)\n",
    "\n",
    "imp = SimpleImputer(); Xtr = imp.fit_transform(X_train); Xte = imp.transform(X_test)\n",
    "Xtr_s, Xte_s = standardize_train_test(Xtr, Xte)\n",
    "\n",
    "est = LogisticRegression(solver='liblinear', random_state=RANDOM_STATE)\n",
    "rfecv = RFECV(estimator=est, step=2, cv=5, scoring='f1_macro', n_jobs=-1)\n",
    "t0 = time.perf_counter(); rfecv.fit(Xtr_s, y_train); t_sel = time.perf_counter() - t0\n",
    "nsel = int(getattr(rfecv, 'n_features_', Xtr.shape[1]))\n",
    "\n",
    "Xtr_sel = rfecv.transform(Xtr_s); Xte_sel = rfecv.transform(Xte_s)\n",
    "final = LogisticRegression(solver='liblinear', random_state=RANDOM_STATE)\n",
    "t0 = time.perf_counter(); final.fit(Xtr_sel, y_train); t_fit = time.perf_counter() - t0\n",
    "yp = final.predict(Xte_sel)\n",
    "\n",
    "print('RFECV')\n",
    "print('n_features seleccionadas:', nsel)\n",
    "print(f'Accuracy: {accuracy_score(y_test, yp):.4f}  |  F1-macro: {f1_score(y_test, yp, average=\"macro\"):.4f}  |  tiempo_total: {t_sel + t_fit:.3f}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf08ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OBLIGATORIO: Compara RFECV con filtro en las mismas condiciones (mismo dataset, misma imputación/escalado, mismo número de características) y explica cuál es mejor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "de869d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OBLIGATORIO: Eligen RFECV y filtro las mismas variables?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "22393712",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPCIONAL: Repite todo para un problema de regresión"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a199ed",
   "metadata": {},
   "source": [
    "### ENTREGABLE: Escribe en el documento de la práctica (formato libre) un texto explicando los resultados obtenidos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) SelectFromModel\n",
    "Primero seleccionamos características y luego reentrenamos para comparar solo el efecto de la selección."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2f5198e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "imp = SimpleImputer()\n",
    "Xtr = imp.fit_transform(X_train)\n",
    "Xte = imp.transform(X_test)\n",
    "Xtr_s, Xte_s = standardize_train_test(Xtr, Xte)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c6820ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "# L1 como selector\n",
    "sel1 = SelectFromModel(\n",
    "    LogisticRegression(penalty=\"l1\", solver=\"liblinear\", random_state=RANDOM_STATE)\n",
    ")\n",
    "t0 = time.perf_counter()\n",
    "sel1.fit(Xtr_s, y_train)\n",
    "t_sel1 = time.perf_counter() - t0\n",
    "Xtr_sel = sel1.transform(Xtr_s)\n",
    "Xte_sel = sel1.transform(Xte_s)\n",
    "clf = LogisticRegression(penalty=\"l2\", solver=\"liblinear\", random_state=RANDOM_STATE)\n",
    "t0 = time.perf_counter()\n",
    "clf.fit(Xtr_sel, y_train)\n",
    "t_fit1 = time.perf_counter() - t0\n",
    "yp = clf.predict(Xte_sel)\n",
    "rows.append(\n",
    "    [\n",
    "        \"SFM(L1 LR) + LR L2\",\n",
    "        int(sel1.get_support().sum()),\n",
    "        accuracy_score(y_test, yp),\n",
    "        f1_score(y_test, yp, average=\"macro\"),\n",
    "        t_sel1 + t_fit1,\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f5957bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomForest como selector\n",
    "sel2 = SelectFromModel(\n",
    "    RandomForestClassifier(n_estimators=200, random_state=RANDOM_STATE, n_jobs=-1)\n",
    ")\n",
    "t0 = time.perf_counter()\n",
    "sel2.fit(Xtr_s, y_train)\n",
    "t_sel2 = time.perf_counter() - t0\n",
    "Xtr_sel = sel2.transform(Xtr_s)\n",
    "Xte_sel = sel2.transform(Xte_s)\n",
    "clf = LogisticRegression(penalty=\"l2\", solver=\"liblinear\", random_state=RANDOM_STATE)\n",
    "t0 = time.perf_counter()\n",
    "clf.fit(Xtr_sel, y_train)\n",
    "t_fit2 = time.perf_counter() - t0\n",
    "yp = clf.predict(Xte_sel)\n",
    "rows.append(\n",
    "    [\n",
    "        \"SFM(RandomForest) + LR L2\",\n",
    "        int(sel2.get_support().sum()),\n",
    "        accuracy_score(y_test, yp),\n",
    "        f1_score(y_test, yp, average=\"macro\"),\n",
    "        t_sel2 + t_fit2,\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tratamiento</th>\n",
       "      <th>n_features</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1-macro</th>\n",
       "      <th>tiempo_total_s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SFM(L1 LR) + LR L2</td>\n",
       "      <td>14</td>\n",
       "      <td>0.958042</td>\n",
       "      <td>0.955031</td>\n",
       "      <td>0.002982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SFM(RandomForest) + LR L2</td>\n",
       "      <td>9</td>\n",
       "      <td>0.951049</td>\n",
       "      <td>0.947330</td>\n",
       "      <td>0.141060</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Tratamiento  n_features  Accuracy  F1-macro  tiempo_total_s\n",
       "0         SFM(L1 LR) + LR L2          14  0.958042  0.955031        0.002982\n",
       "1  SFM(RandomForest) + LR L2           9  0.951049  0.947330        0.141060"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(rows, columns=['Tratamiento', 'n_features', 'Accuracy', 'F1-macro', 'tiempo_total_s'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0d63ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OBLIGATORIO: Compara los tres métodos de selección de características en las mismas condiciones \n",
    "# (usando el mismo dataset, misma imputación/escalado, mismo número de características) y explica cuál es mejor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5f3c748f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OBLIGATORIO: Elige este método las mismas variables que los anteriores? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d488fbef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPCIONAL: Repite todo para un problema de regresión\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389908f5",
   "metadata": {},
   "source": [
    "### ENTREGABLE: Escribe en el documento de la práctica (formato libre) un texto explicando los resultados obtenidos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7) Selección de instancias\n",
    "Reducimos deliberadamente el tamaño del conjunto de entrenamiento y comparamos con entrenar con todo el train."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2485bc3f",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "- **CNN** (Condensed Nearest Neighbour): condensa el train manteniendo representantes.\n",
    "- **ENN** (Edited Nearest Neighbours): elimina ejemplos conflictivos.\n",
    "\n",
    "> Requiere imbalanced-learn: pip install imbalanced-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "33337d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import CondensedNearestNeighbour, EditedNearestNeighbours\n",
    "\n",
    "# Preprocesado (imputación + escalado con train)\n",
    "imp = SimpleImputer()\n",
    "Xtr = imp.fit_transform(X_train)\n",
    "Xte = imp.transform(X_test)\n",
    "sc = StandardScaler()\n",
    "Xtr_s = sc.fit_transform(Xtr)\n",
    "Xte_s = sc.transform(Xte)\n",
    "\n",
    "rows = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "69f7b480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A) Todo el train\n",
    "clf_full = LogisticRegression(solver=\"liblinear\", random_state=RANDOM_STATE)\n",
    "t0 = time.perf_counter()\n",
    "clf_full.fit(Xtr_s, y_train)\n",
    "t_full = time.perf_counter() - t0\n",
    "yp_full = clf_full.predict(Xte_s)\n",
    "acc_full = accuracy_score(y_test, yp_full)\n",
    "f1_full = f1_score(y_test, yp_full, average=\"macro\")\n",
    "rows.append([\"Todo el train\", Xtr_s.shape[0], acc_full, f1_full, t_full])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "64678af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# B) CNN (condensado)\n",
    "cnn = CondensedNearestNeighbour(random_state=RANDOM_STATE)\n",
    "Xtr_cnn, ytr_cnn = cnn.fit_resample(Xtr_s, y_train)\n",
    "clf_cnn = LogisticRegression(solver=\"liblinear\", random_state=RANDOM_STATE)\n",
    "t0 = time.perf_counter()\n",
    "clf_cnn.fit(Xtr_cnn, ytr_cnn)\n",
    "t_cnn = time.perf_counter() - t0\n",
    "yp_cnn = clf_cnn.predict(Xte_s)\n",
    "rows.append(\n",
    "    [\n",
    "        \"CNN (condensado)\",\n",
    "        Xtr_cnn.shape[0],\n",
    "        accuracy_score(y_test, yp_cnn),\n",
    "        f1_score(y_test, yp_cnn, average=\"macro\"),\n",
    "        t_cnn,\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8dc5f103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C) ENN (edición)\n",
    "enn = EditedNearestNeighbours()\n",
    "Xtr_enn, ytr_enn = enn.fit_resample(Xtr_s, y_train)\n",
    "clf_enn = LogisticRegression(solver=\"liblinear\", random_state=RANDOM_STATE)\n",
    "t0 = time.perf_counter()\n",
    "clf_enn.fit(Xtr_enn, ytr_enn)\n",
    "t_enn = time.perf_counter() - t0\n",
    "yp_enn = clf_enn.predict(Xte_s)\n",
    "rows.append(\n",
    "    [\n",
    "        \"ENN (edición)\",\n",
    "        Xtr_enn.shape[0],\n",
    "        accuracy_score(y_test, yp_enn),\n",
    "        f1_score(y_test, yp_enn, average=\"macro\"),\n",
    "        t_enn,\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tratamiento</th>\n",
       "      <th>n_instancias_train</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1-macro</th>\n",
       "      <th>tiempo_entreno_s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Todo el train</td>\n",
       "      <td>426</td>\n",
       "      <td>0.958042</td>\n",
       "      <td>0.955031</td>\n",
       "      <td>0.002005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CNN (condensado)</td>\n",
       "      <td>201</td>\n",
       "      <td>0.951049</td>\n",
       "      <td>0.948116</td>\n",
       "      <td>0.000971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENN (edición)</td>\n",
       "      <td>408</td>\n",
       "      <td>0.951049</td>\n",
       "      <td>0.948116</td>\n",
       "      <td>0.002074</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Tratamiento  n_instancias_train  Accuracy  F1-macro  tiempo_entreno_s\n",
       "0     Todo el train                 426  0.958042  0.955031          0.002005\n",
       "1  CNN (condensado)                 201  0.951049  0.948116          0.000971\n",
       "2     ENN (edición)                 408  0.951049  0.948116          0.002074"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "pd.DataFrame(\n",
    "    rows,\n",
    "    columns=[\n",
    "        \"Tratamiento\",\n",
    "        \"n_instancias_train\",\n",
    "        \"Accuracy\",\n",
    "        \"F1-macro\",\n",
    "        \"tiempo_entreno_s\",\n",
    "    ],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "97755fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OBLIGATORIO: Usa un nuevo dataset de clasificación y repítelo todo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b95c9d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPCIONAL: Usa un dataset de regresión"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c5e663",
   "metadata": {},
   "source": [
    "### ENTREGABLE: Escribe en el documento de la práctica (formato libre) un texto explicando los resultados obtenidos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demostración de Pipeline (sin entregables)\n",
    "Esto no es necesario para entender los métodos; simplemente muestra cómo encadenar pasos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline → Accuracy: 0.9580 | F1-macro: 0.9550 | tiempo: 0.005s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipe = Pipeline(\n",
    "    [\n",
    "        (\"imp\", SimpleImputer()),\n",
    "        (\"sc\", StandardScaler()),\n",
    "        (\n",
    "            \"sel\",\n",
    "            SelectFromModel(\n",
    "                LogisticRegression(\n",
    "                    penalty=\"l1\", solver=\"liblinear\", random_state=RANDOM_STATE\n",
    "                )\n",
    "            ),\n",
    "        ),\n",
    "        (\n",
    "            \"clf\",\n",
    "            LogisticRegression(\n",
    "                penalty=\"l2\", solver=\"liblinear\", random_state=RANDOM_STATE\n",
    "            ),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "t0 = time.perf_counter()\n",
    "pipe.fit(X_train, y_train)\n",
    "t = time.perf_counter() - t0\n",
    "yp = pipe.predict(X_test)\n",
    "print(\n",
    "    f\"Pipeline → Accuracy: {accuracy_score(y_test, yp):.4f} | F1-macro: {f1_score(y_test, yp, average='macro'):.4f} | tiempo: {t:.3f}s\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60bb4e47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
